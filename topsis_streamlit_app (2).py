import streamlit as st
import numpy as np
import pandas as pd

st.set_page_config(page_title="TOPSIS avec Entropie", layout="wide", page_icon="üìä")

# Titre principal
st.title("üéØ M√©thode TOPSIS avec Entropie et Poids Hi√©rarchiques")
st.markdown("---")

# Initialisation de session_state
if 'decision_matrix' not in st.session_state:
    st.session_state.decision_matrix = None
if 'main_criteria' not in st.session_state:
    st.session_state.main_criteria = []

# Sidebar pour la configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    num_alternatives = st.number_input("Nombre d'alternatives", min_value=2, max_value=20, value=4)
    num_main_criteria = st.number_input("Nombre de crit√®res principaux", min_value=1, max_value=10, value=3)
    
    st.markdown("---")
    st.info("üìö **M√©thode TOPSIS**\n\nCombine les poids d'entropie (objectifs) et les poids subjectifs pour un classement optimal des alternatives.")

# Fonction pour calculer l'entropie
def calculate_entropy_weights(matrix):
    """Calcule les poids d'entropie pour chaque crit√®re"""
    m, n = matrix.shape
    k = 1 / np.log(m)
    
    # Normalisation
    P = matrix / matrix.sum(axis=0)
    
    # Calcul de Z (√©viter log(0))
    P_safe = np.where(P == 0, 1e-10, P)
    Z = P_safe / P_safe.sum(axis=0)
    
    # Calcul de l'entropie
    e = -k * np.sum(Z * np.log(Z), axis=0)
    
    # Calcul des poids
    w_entropy = (1 - e) / np.sum(1 - e)
    
    return w_entropy, e

# Fonction pour combiner les poids
def combine_weights(w_entropy, w_subjective):
    """Combine les poids d'entropie et subjectifs"""
    w_combined = (w_entropy * w_subjective) / np.sum(w_entropy * w_subjective)
    return w_combined

# Fonction TOPSIS compl√®te
def topsis_analysis(matrix, weights, criteria_types):
    """
    Effectue l'analyse TOPSIS compl√®te
    matrix: matrice de d√©cision
    weights: poids combin√©s
    criteria_types: 'benefit' ou 'cost' pour chaque crit√®re
    """
    m, n = matrix.shape
    
    # √âtape 2: Normalisation
    P = matrix / matrix.sum(axis=0)
    
    # √âtape 6: Application des poids
    U = P * weights
    
    # √âtape 7: Solutions id√©ales
    A_plus = np.zeros(n)
    A_minus = np.zeros(n)
    
    for j in range(n):
        if criteria_types[j] == 'benefit':
            A_plus[j] = np.max(U[:, j])
            A_minus[j] = np.min(U[:, j])
        else:  # cost
            A_plus[j] = np.min(U[:, j])
            A_minus[j] = np.max(U[:, j])
    
    # √âtape 8: Calcul des distances
    S_plus = np.sqrt(np.sum((U - A_plus)**2, axis=1))
    S_minus = np.sqrt(np.sum((U - A_minus)**2, axis=1))
    
    # √âtape 9: Proximit√© relative
    C = S_minus / (S_plus + S_minus)
    
    # √âtape 10: Classement
    ranking = np.argsort(-C) + 1
    
    return {
        'normalized_matrix': P,
        'weighted_matrix': U,
        'A_plus': A_plus,
        'A_minus': A_minus,
        'S_plus': S_plus,
        'S_minus': S_minus,
        'proximity': C,
        'ranking': ranking
    }

def get_color_gradient(value, min_val=0, max_val=1):
    """G√©n√®re une couleur en d√©grad√© rouge-jaune-vert"""
    normalized = (value - min_val) / (max_val - min_val) if max_val > min_val else 0.5
    
    if normalized < 0.5:
        # Rouge vers Jaune
        r = 255
        g = int(255 * (normalized * 2))
        b = 0
    else:
        # Jaune vers Vert
        r = int(255 * (2 - normalized * 2))
        g = 255
        b = 0
    
    return f'rgba({r}, {g}, {b}, 0.3)'

# Onglets principaux
tab1, tab2, tab3, tab4 = st.tabs(["üìù Crit√®res", "üìä Matrice de D√©cision", "üßÆ Calculs", "üìà R√©sultats"])

with tab1:
    st.header("D√©finition des Crit√®res Principaux et Sous-crit√®res")
    
    main_criteria_data = []
    
    for i in range(num_main_criteria):
        st.subheader(f"üîπ Crit√®re Principal {i+1}")
        
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            main_name = st.text_input(f"Nom", value=f"Crit√®re Principal {i+1}", key=f"main_{i}")
        with col2:
            main_weight = st.number_input(f"Poids subjectif", min_value=0.0, max_value=1.0, value=round(1/num_main_criteria, 3), step=0.01, key=f"weight_{i}")
        with col3:
            num_sub = st.number_input(f"Nb sous-crit√®res", min_value=1, max_value=10, value=2, key=f"numsub_{i}")
        
        sub_criteria = []
        for j in range(num_sub):
            col_a, col_b = st.columns([3, 1])
            with col_a:
                sub_name = st.text_input(f"  ‚îî‚îÄ Sous-crit√®re {i+1}.{j+1}", value=f"Sous-crit√®re {i+1}.{j+1}", key=f"sub_{i}_{j}")
            with col_b:
                sub_type = st.selectbox(f"Type", ["benefit", "cost"], key=f"type_{i}_{j}")
            
            sub_criteria.append({
                'name': sub_name,
                'type': sub_type
            })
        
        main_criteria_data.append({
            'name': main_name,
            'weight': main_weight,
            'sub_criteria': sub_criteria
        })
        
        st.markdown("---")
    
    st.session_state.main_criteria = main_criteria_data
    
    # V√©rification des poids
    total_weight = sum([mc['weight'] for mc in main_criteria_data])
    if abs(total_weight - 1.0) > 0.01:
        st.warning(f"‚ö†Ô∏è La somme des poids subjectifs est {total_weight:.3f}. Elle devrait √™tre √©gale √† 1.0")
    else:
        st.success(f"‚úÖ Somme des poids subjectifs = {total_weight:.3f}")

with tab2:
    st.header("Matrice de D√©cision")
    
    if st.session_state.main_criteria:
        # Cr√©er la liste de tous les sous-crit√®res
        all_sub_criteria = []
        criteria_types = []
        main_criteria_indices = []
        
        for mc_idx, mc in enumerate(st.session_state.main_criteria):
            for sc in mc['sub_criteria']:
                all_sub_criteria.append(f"{mc['name']}: {sc['name']}")
                criteria_types.append(sc['type'])
                main_criteria_indices.append(mc_idx)
        
        num_sub_criteria = len(all_sub_criteria)
        
        st.info(f"üìã Total: {num_alternatives} alternatives √ó {num_sub_criteria} sous-crit√®res")
        
        # Cr√©er le DataFrame pour la saisie
        if st.session_state.decision_matrix is None or st.session_state.decision_matrix.shape != (num_alternatives, num_sub_criteria):
            st.session_state.decision_matrix = pd.DataFrame(
               matrix = np.random.uniform(1, 10, size=(num_alternatives, num_sub_criteria))
                columns=all_sub_criteria,
                index=[f"Alternative {i+1}" for i in range(num_alternatives)]
            )
        
        st.markdown("### üìù Saisir les valeurs de performance")
        edited_df = st.data_editor(
            st.session_state.decision_matrix,
            use_container_width=True,
            num_rows="fixed"
        )
        
        st.session_state.decision_matrix = edited_df
        
        # Afficher les types de crit√®res
        st.markdown("### üè∑Ô∏è Types de crit√®res")
        types_df = pd.DataFrame({
            'Sous-crit√®re': all_sub_criteria,
            'Type': criteria_types,
            'Crit√®re Principal': [st.session_state.main_criteria[idx]['name'] for idx in main_criteria_indices]
        })
        st.dataframe(types_df, use_container_width=True)

with tab3:
    st.header("Calculs D√©taill√©s")
    
    if st.session_state.decision_matrix is not None and st.button("üöÄ Lancer les calculs", type="primary", use_container_width=True):
        
        matrix = st.session_state.decision_matrix.values
        
        # Calculer les poids d'entropie pour chaque sous-crit√®re
        w_entropy, entropy_values = calculate_entropy_weights(matrix)
        
        # Pr√©parer les poids subjectifs des sous-crit√®res
        w_subjective = []
        for mc_idx, mc in enumerate(st.session_state.main_criteria):
            main_weight = mc['weight']
            num_sub = len(mc['sub_criteria'])
            # R√©partir le poids principal √©galement entre les sous-crit√®res
            for _ in range(num_sub):
                w_subjective.append(main_weight / num_sub)
        
        w_subjective = np.array(w_subjective)
        
        # Normaliser les poids subjectifs
        w_subjective = w_subjective / w_subjective.sum()
        
        # Combiner les poids
        w_combined = combine_weights(w_entropy, w_subjective)
        
        # Extraire les types de crit√®res
        criteria_types = []
        for mc in st.session_state.main_criteria:
            for sc in mc['sub_criteria']:
                criteria_types.append(sc['type'])
        
        # Analyse TOPSIS
        results = topsis_analysis(matrix, w_combined, criteria_types)
        
        st.session_state.results = {
            'w_entropy': w_entropy,
            'entropy_values': entropy_values,
            'w_subjective': w_subjective,
            'w_combined': w_combined,
            'topsis': results,
            'criteria_types': criteria_types
        }
        
        # Affichage des r√©sultats interm√©diaires
        st.success("‚úÖ Calculs termin√©s avec succ√®s!")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Nombre d'alternatives", num_alternatives)
        with col2:
            st.metric("Nombre de sous-crit√®res", len(w_entropy))
        with col3:
            best_alt = np.argmax(results['proximity']) + 1
            st.metric("Meilleure alternative", f"Alternative {best_alt}", delta="Optimal")
        
        st.markdown("---")
        
        # Tableau des poids
        st.markdown("### ‚öñÔ∏è Comparaison des Poids")
        weights_df = pd.DataFrame({
            'Sous-crit√®re': st.session_state.decision_matrix.columns,
            'Entropie (Objectif)': w_entropy,
            'Subjectif': w_subjective,
            'Combin√©': w_combined,
            'Type': criteria_types
        })
        
        st.dataframe(
            weights_df.style.format({
                'Entropie (Objectif)': '{:.4f}',
                'Subjectif': '{:.4f}',
                'Combin√©': '{:.4f}'
            }).background_gradient(subset=['Combin√©'], cmap='YlGn'),
            use_container_width=True
        )
        
        # Graphique simple des poids avec des barres
        st.markdown("### üìä Visualisation des Poids")
        chart_data = pd.DataFrame({
            'Entropie': w_entropy,
            'Subjectif': w_subjective,
            'Combin√©': w_combined
        }, index=[f'C{i+1}' for i in range(len(w_entropy))])
        st.bar_chart(chart_data)
        
        # Matrice normalis√©e
        st.markdown("### üìê Matrice Normalis√©e")
        normalized_df = pd.DataFrame(
            results['normalized_matrix'],
            columns=st.session_state.decision_matrix.columns,
            index=st.session_state.decision_matrix.index
        )
        st.dataframe(normalized_df.style.format('{:.4f}').background_gradient(cmap='Blues'), use_container_width=True)
        
        # Matrice pond√©r√©e
        st.markdown("### üéØ Matrice Pond√©r√©e (U)")
        weighted_df = pd.DataFrame(
            results['weighted_matrix'],
            columns=st.session_state.decision_matrix.columns,
            index=st.session_state.decision_matrix.index
        )
        st.dataframe(weighted_df.style.format('{:.4f}').background_gradient(cmap='Greens'), use_container_width=True)
        
        # Solutions id√©ales
        st.markdown("### üéØ Solutions Id√©ales")
        col_a, col_b = st.columns(2)
        with col_a:
            st.info("**Solution Positive Id√©ale (A+)**")
            ideal_pos_df = pd.DataFrame({
                'Crit√®re': [f'C{i+1}' for i in range(len(results['A_plus']))],
                'Valeur': results['A_plus']
            })
            st.dataframe(ideal_pos_df.style.format({'Valeur': '{:.4f}'}), use_container_width=True)
        
        with col_b:
            st.warning("**Solution N√©gative Id√©ale (A-)**")
            ideal_neg_df = pd.DataFrame({
                'Crit√®re': [f'C{i+1}' for i in range(len(results['A_minus']))],
                'Valeur': results['A_minus']
            })
            st.dataframe(ideal_neg_df.style.format({'Valeur': '{:.4f}'}), use_container_width=True)

with tab4:
    st.header("R√©sultats Finaux")
    
    if 'results' in st.session_state and st.session_state.results is not None:
        results = st.session_state.results
        topsis = results['topsis']
        
        # Tableau de classement
        st.markdown("### üèÜ Classement Final")
        
        ranking_df = pd.DataFrame({
            'Alternative': st.session_state.decision_matrix.index,
            'S+ (Distance PIS)': topsis['S_plus'],
            'S- (Distance NIS)': topsis['S_minus'],
            'Proximit√© Relative (Ci)': topsis['proximity'],
            'Rang': topsis['ranking']
        }).sort_values('Rang')
        
        st.dataframe(
            ranking_df.style.format({
                'S+ (Distance PIS)': '{:.4f}',
                'S- (Distance NIS)': '{:.4f}',
                'Proximit√© Relative (Ci)': '{:.4f}'
            }).background_gradient(subset=['Proximit√© Relative (Ci)'], cmap='RdYlGn'),
            use_container_width=True
        )
        
        # Affichage visuel du classement
        st.markdown("### üìä Visualisation des Proximit√©s")
        prox_chart = pd.DataFrame({
            'Proximit√©': topsis['proximity']
        }, index=st.session_state.decision_matrix.index)
        st.bar_chart(prox_chart)
        
        # Comparaison des distances
        st.markdown("### üìè Comparaison des Distances")
        dist_chart = pd.DataFrame({
            'Distance √† PIS (S+)': topsis['S_plus'],
            'Distance √† NIS (S-)': topsis['S_minus']
        }, index=st.session_state.decision_matrix.index)
        st.bar_chart(dist_chart)
        
        # Podium des 3 meilleures alternatives
        st.markdown("### ü•á Podium")
        col1, col2, col3 = st.columns(3)
        
        sorted_indices = np.argsort(-topsis['proximity'])
        
        if len(sorted_indices) >= 1:
            with col1:
                st.success("**ü•á 1√®re Place**")
                idx = sorted_indices[0]
                st.metric(
                    st.session_state.decision_matrix.index[idx],
                    f"{topsis['proximity'][idx]:.4f}",
                    delta="Meilleure"
                )
        
        if len(sorted_indices) >= 2:
            with col2:
                st.info("**ü•à 2√®me Place**")
                idx = sorted_indices[1]
                st.metric(
                    st.session_state.decision_matrix.index[idx],
                    f"{topsis['proximity'][idx]:.4f}"
                )
        
        if len(sorted_indices) >= 3:
            with col3:
                st.warning("**ü•â 3√®me Place**")
                idx = sorted_indices[2]
                st.metric(
                    st.session_state.decision_matrix.index[idx],
                    f"{topsis['proximity'][idx]:.4f}"
                )
        
        st.markdown("---")
        
        # Analyse comparative d√©taill√©e
        st.markdown("### üîç Analyse Comparative D√©taill√©e")
        
        selected_alts = st.multiselect(
            "S√©lectionner les alternatives √† comparer",
            options=list(st.session_state.decision_matrix.index),
            default=list(st.session_state.decision_matrix.index)[:min(3, num_alternatives)]
        )
        
        if selected_alts:
            comparison_data = []
            for alt in selected_alts:
                idx = list(st.session_state.decision_matrix.index).index(alt)
                comparison_data.append({
                    'Alternative': alt,
                    'Proximit√©': topsis['proximity'][idx],
                    'Rang': topsis['ranking'][idx],
                    'Distance PIS': topsis['S_plus'][idx],
                    'Distance NIS': topsis['S_minus'][idx]
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(
                comparison_df.style.format({
                    'Proximit√©': '{:.4f}',
                    'Distance PIS': '{:.4f}',
                    'Distance NIS': '{:.4f}'
                }),
                use_container_width=True
            )
            
            # Performances par crit√®re pour les alternatives s√©lectionn√©es
            st.markdown("#### üìä Performances Pond√©r√©es par Crit√®re")
            perf_data = {}
            for alt in selected_alts:
                idx = list(st.session_state.decision_matrix.index).index(alt)
                perf_data[alt] = topsis['weighted_matrix'][idx]
            
            perf_df = pd.DataFrame(
                perf_data,
                index=[f'C{i+1}' for i in range(len(st.session_state.decision_matrix.columns))]
            )
            st.bar_chart(perf_df)
        
        # Statistiques globales
        st.markdown("### üìâ Statistiques Globales")
        col_a, col_b, col_c, col_d = st.columns(4)
        
        with col_a:
            st.metric("Proximit√© Moyenne", f"{np.mean(topsis['proximity']):.4f}")
        with col_b:
            st.metric("√âcart-type", f"{np.std(topsis['proximity']):.4f}")
        with col_c:
            st.metric("Minimum", f"{np.min(topsis['proximity']):.4f}")
        with col_d:
            st.metric("Maximum", f"{np.max(topsis['proximity']):.4f}")
        
        # Analyse de la distribution
        st.markdown("### üìä Distribution des Proximit√©s")
        bins = np.linspace(0, 1, 11)
        hist, _ = np.histogram(topsis['proximity'], bins=bins)
        hist_df = pd.DataFrame({
            'Fr√©quence': hist
        }, index=[f'{bins[i]:.1f}-{bins[i+1]:.1f}' for i in range(len(bins)-1)])
        st.bar_chart(hist_df)
        
        # T√©l√©chargement des r√©sultats
        st.markdown("### üíæ Exporter les R√©sultats")
        
        col_x, col_y, col_z = st.columns(3)
        
        with col_x:
            csv = ranking_df.to_csv(index=False)
            st.download_button(
                label="üì• Classement (CSV)",
                data=csv,
                file_name="topsis_ranking.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col_y:
            weights_csv = pd.DataFrame({
                'Crit√®re': st.session_state.decision_matrix.columns,
                'Poids_Entropie': results['w_entropy'],
                'Poids_Subjectif': results['w_subjective'],
                'Poids_Combin√©': results['w_combined']
            }).to_csv(index=False)
            st.download_button(
                label="üì• Poids (CSV)",
                data=weights_csv,
                file_name="topsis_weights.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col_z:
            # Export complet
            all_data = ranking_df.copy()
            all_data['Matrice_Originale'] = [
                str(st.session_state.decision_matrix.iloc[i].to_dict())
                for i in range(len(st.session_state.decision_matrix))
            ]
            export_csv = all_data.to_csv(index=False)
            st.download_button(
                label="üì• Export Complet (CSV)",
                data=export_csv,
                file_name="topsis_export_complet.csv",
                mime="text/csv",
                use_container_width=True
            )
    
    else:
        st.info("üëÜ Veuillez d'abord lancer les calculs dans l'onglet 'Calculs'")
        st.markdown("""
        ### üìã Instructions:
        1. Allez dans l'onglet **Crit√®res** pour d√©finir vos crit√®res
        2. Allez dans l'onglet **Matrice de D√©cision** pour saisir les donn√©es
        3. Cliquez sur **Lancer les calculs** dans l'onglet **Calculs**
        4. Revenez ici pour voir les r√©sultats
        """)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>üìä <b>Application TOPSIS avec Entropie et Poids Hi√©rarchiques</b></p>
    <p>M√©thode combinant poids objectifs (entropie) et subjectifs pour une prise de d√©cision optimale</p>
    <p style='font-size: 0.8em;'>D√©velopp√© avec Streamlit | Calculs bas√©s sur NumPy et Pandas</p>
</div>
""", unsafe_allow_html=True)
